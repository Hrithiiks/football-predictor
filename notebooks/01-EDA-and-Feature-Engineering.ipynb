{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3d878d-f708-4e91-9e89-7b687fa1efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30 entries, 0 to 29\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   date        30 non-null     datetime64[ns, UTC]\n",
      " 1   home_team   30 non-null     object             \n",
      " 2   away_team   30 non-null     object             \n",
      " 3   home_goals  30 non-null     int64              \n",
      " 4   away_goals  30 non-null     int64              \n",
      " 5   result      30 non-null     object             \n",
      " 6   target      30 non-null     int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(3)\n",
      "memory usage: 1.9+ KB\n",
      "\n",
      "DataFrame Head:\n",
      "                       date                  home_team            away_team  \\\n",
      "0 2025-08-15 19:00:00+00:00               Liverpool FC      AFC Bournemouth   \n",
      "1 2025-08-16 11:30:00+00:00             Aston Villa FC  Newcastle United FC   \n",
      "2 2025-08-16 14:00:00+00:00  Brighton & Hove Albion FC            Fulham FC   \n",
      "3 2025-08-16 14:00:00+00:00             Sunderland AFC   West Ham United FC   \n",
      "4 2025-08-16 14:00:00+00:00       Tottenham Hotspur FC           Burnley FC   \n",
      "\n",
      "   home_goals  away_goals     result  target  \n",
      "0           4           2  HOME_TEAM       1  \n",
      "1           0           0       DRAW       0  \n",
      "2           1           1       DRAW       0  \n",
      "3           3           0  HOME_TEAM       1  \n",
      "4           3           0  HOME_TEAM       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the dataset from our data/raw folder\n",
    "# The '../' means 'go up one directory level' from notebooks/\n",
    "df = pd.read_csv(r'C:\\Users\\HRITHIK S\\MY PROJECTS\\football-predictor\\data\\raw\\premier_league_matches.csv')\n",
    "\n",
    "# 2. Convert 'date' column to datetime objects\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 3. Sort matches chronologically\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# 4. Create our numerical target variable\n",
    "# We'll map HOME_TEAM win to 1, DRAW to 0, and AWAY_TEAM win to 2\n",
    "df['target'] = df['result'].map({'HOME_TEAM': 1, 'DRAW': 0, 'AWAY_TEAM': 2})\n",
    "\n",
    "# --- Verification ---\n",
    "# Use df.info() to see the data types of our columns (Date should be datetime64)\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows with our new 'target' column\n",
    "print(\"\\nDataFrame Head:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2edf55b1-594e-4c78-aaec-3ab4ff20cf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Form Features (Last 5 matches):\n",
      "                        date                  home_team            away_team  \\\n",
      "25 2025-08-30 16:30:00+00:00            Leeds United FC  Newcastle United FC   \n",
      "26 2025-08-31 13:00:00+00:00  Brighton & Hove Albion FC   Manchester City FC   \n",
      "27 2025-08-31 13:00:00+00:00       Nottingham Forest FC   West Ham United FC   \n",
      "28 2025-08-31 15:30:00+00:00               Liverpool FC           Arsenal FC   \n",
      "29 2025-08-31 18:00:00+00:00             Aston Villa FC    Crystal Palace FC   \n",
      "\n",
      "    home_goals  away_goals     result  target  home_form_points  \\\n",
      "25           0           0       DRAW       0               1.5   \n",
      "26           2           1  HOME_TEAM       1               0.5   \n",
      "27           0           3  AWAY_TEAM       2               2.0   \n",
      "28           1           0  HOME_TEAM       1               3.0   \n",
      "29           0           3  AWAY_TEAM       2               0.5   \n",
      "\n",
      "    home_form_goals_scored  home_form_goals_conceded  \\\n",
      "25                     0.5                       2.5   \n",
      "26                     0.5                       1.5   \n",
      "27                     2.0                       1.0   \n",
      "28                     3.5                       2.0   \n",
      "29                     0.0                       0.5   \n",
      "\n",
      "    home_form_goal_difference  away_form_points  away_form_goals_scored  \\\n",
      "25                       -2.0               0.5                     1.0   \n",
      "26                       -1.0               1.5                     2.0   \n",
      "27                        1.0               0.0                     0.5   \n",
      "28                        1.5               3.0                     3.0   \n",
      "29                       -0.5               1.0                     0.5   \n",
      "\n",
      "    away_form_goals_conceded  away_form_goal_difference  \n",
      "25                       1.5                       -0.5  \n",
      "26                       1.0                        1.0  \n",
      "27                       4.0                       -3.5  \n",
      "28                       0.0                        3.0  \n",
      "29                       0.5                        0.0  \n"
     ]
    }
   ],
   "source": [
    "# Define the number of past games to consider for form\n",
    "ROLLING_WINDOW = 5\n",
    "\n",
    "# A list of all unique team names\n",
    "teams = pd.unique(df[['home_team', 'away_team']].values.ravel('K'))\n",
    "\n",
    "# Create empty columns for our new form features, initializing them with 0.0\n",
    "form_features = [\n",
    "    'form_points', 'form_goals_scored', 'form_goals_conceded', 'form_goal_difference'\n",
    "]\n",
    "for side in ['home', 'away']:\n",
    "    for feature in form_features:\n",
    "        df[f'{side}_{feature}'] = 0.0\n",
    "\n",
    "# --- Calculate Form for Each Team ---\n",
    "for team in teams:\n",
    "    # Filter for all matches played by the current team\n",
    "    team_matches = df[(df['home_team'] == team) | (df['away_team'] == team)]\n",
    "\n",
    "    # Calculate stats for this team in each of its matches\n",
    "    # Points awarded: 3 for a win, 1 for a draw, 0 for a loss\n",
    "    points = team_matches.apply(lambda row: 3 if (row['home_team'] == team and row['result'] == 'HOME_TEAM') or \\\n",
    "                                                 (row['away_team'] == team and row['result'] == 'AWAY_TEAM') else \\\n",
    "                                             1 if row['result'] == 'DRAW' else 0, axis=1)\n",
    "    goals_scored = team_matches.apply(lambda row: row['home_goals'] if row['home_team'] == team else row['away_goals'], axis=1)\n",
    "    goals_conceded = team_matches.apply(lambda row: row['away_goals'] if row['home_team'] == team else row['home_goals'], axis=1)\n",
    "\n",
    "    # --- Calculate Rolling Averages ---\n",
    "    # We use .shift(1) to get the form BEFORE the current match to prevent data leakage.\n",
    "    # min_periods=1 allows us to get a value even for the first few games.\n",
    "    rolling_stats = {\n",
    "        'form_points': points.shift(1).rolling(window=ROLLING_WINDOW, min_periods=1).mean(),\n",
    "        'form_goals_scored': goals_scored.shift(1).rolling(window=ROLLING_WINDOW, min_periods=1).mean(),\n",
    "        'form_goals_conceded': goals_conceded.shift(1).rolling(window=ROLLING_WINDOW, min_periods=1).mean(),\n",
    "        'form_goal_difference': (goals_scored - goals_conceded).shift(1).rolling(window=ROLLING_WINDOW, min_periods=1).mean()\n",
    "    }\n",
    "\n",
    "    # --- Update the main DataFrame ---\n",
    "    # We find the original indices of the team's matches and update the correct rows (home vs away)\n",
    "    for feature, values in rolling_stats.items():\n",
    "        df.loc[team_matches.index, f'home_{feature}'] = team_matches.index.map(values).where(team_matches['home_team'] == team, df.loc[team_matches.index, f'home_{feature}'])\n",
    "        df.loc[team_matches.index, f'away_{feature}'] = team_matches.index.map(values).where(team_matches['away_team'] == team, df.loc[team_matches.index, f'away_{feature}'])\n",
    "\n",
    "# The first few matches for each team won't have 5 previous games, creating 'NaN' (Not a Number) values.\n",
    "# We'll fill these with 0.\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# --- Verification ---\n",
    "# Display the last 5 rows to see the new form features for recent games\n",
    "print(\"DataFrame with Form Features (Last 5 matches):\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afbc6473-0d7f-4320-b3b6-38b10c005341",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Select our features (the 'clues') and the target (the 'answer')\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     __check_build,\n\u001b[0;32m     71\u001b[0m     _distributor_init,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_missing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scalar_nan\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_indexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     _safe_indexing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     resample,\n\u001b[0;32m     19\u001b[0m     shuffle,\n\u001b[0;32m     20\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Select our features (the 'clues') and the target (the 'answer')\n",
    "features = [\n",
    "    'home_form_points', 'home_form_goals_scored', 'home_form_goals_conceded', 'home_form_goal_difference',\n",
    "    'away_form_points', 'away_form_goals_scored', 'away_form_goals_conceded', 'away_form_goal_difference'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# 2. Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initialize and train our Logistic Regression model\n",
    "# The model 'learns' the relationship between X_train and y_train\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model's accuracy on the unseen test data\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Our first model's accuracy on the test set is: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0f18d-b80c-4356-97e0-acbbdeb717a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
